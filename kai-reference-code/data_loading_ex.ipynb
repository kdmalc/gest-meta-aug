{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a187dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an old config file\n",
    "## Most of this is not relevant\n",
    "## The only things that are relevant are those related to dataloading\n",
    "## I will try to delete most of the irrelvant stuff\n",
    "\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "NUM_CHANNELS = 16  # Note that ELEC573Net is hardcoded in, doesn't use this...\n",
    "NUM_TRAIN_GESTURES = 8  # For pretrained models\n",
    "NUM_FT_GESTURES = 1  # Oneshot finetuning\n",
    "\n",
    "config = {}\n",
    "\n",
    "config[\"feature_engr\"] = \"None\"  # TODO: Is this up to date? Idk if this is relevant to meta-aug\n",
    "config[\"time_steps\"] = 1  # TODO: Is this up to date? Idk if this is relevant to meta-aug\n",
    "config[\"sequence_length\"] = 64  # TODO: Is this up to date? Idk if this is relevant to meta-aug\n",
    "config[\"num_train_gesture_trials\"] = 9  # TODO: Is this up to date? Idk if this is relevant to meta-aug\n",
    "config[\"num_ft_gesture_trials\"] = 1  # TODO: Is this up to date? Idk if this is relevant to meta-aug\n",
    "config[\"num_pretrain_users\"] = 24  # TODO: Is this up to date? Idk if this is relevant to meta-aug\n",
    "config[\"num_testft_users\"] = 4  # TODO: Is this up to date? Idk if this is relevant to meta-aug\n",
    "config[\"timestamp\"] = timestamp\n",
    "config[\"num_classes\"] = 10  # TODO: Is this up to date? Idk if this is relevant to meta-aug\n",
    "config[\"verbose\"] = False\n",
    "config[\"num_total_users\"] = 32\n",
    "\n",
    "config[\"multimodal\"] = True\n",
    "config['emg_in_ch'] = 16\n",
    "config['imu_in_ch'] = 72\n",
    "config['demo_in_dim'] = 12\n",
    "\n",
    "# ADDING MAML SPECIFIC -- this stuff is not yet relevant to the meat aug project\n",
    "config[\"meta_learning\"] = False\n",
    "config[\"n_way\"] = 10\n",
    "config[\"k_shot\"] = 1\n",
    "config[\"q_query\"] = 9  # TODO: Does this need to be 9? If it set it lower does that just make it faster? Does that impact the model? Slightly noiser eval??\n",
    "\n",
    "# These are my data paths, they need to be updated individually unless we want to do relative paths\n",
    "config[\"emg_imu_pkl_full_path\"] = 'C:\\\\Users\\\\kdmen\\\\Box\\\\Yamagami Lab\\\\Data\\\\Meta_Gesture_Project\\\\filtered_datasets\\\\metadata_IMU_EMG_allgestures_allusers.pkl'\n",
    "config[\"pwmd_xlsx_filepath\"] = \"C:\\\\Users\\\\kdmen\\\\Repos\\\\fl-gestures\\\\Biosignal gesture questionnaire for participants with disabilities.xlsx\"\n",
    "config[\"pwoutmd_xlsx_filepath\"] = \"C:\\\\Users\\\\kdmen\\\\Repos\\\\fl-gestures\\\\Biosignal gesture questionnaire for participants without disabilities.xlsx\"\n",
    "config[\"dfs_save_path\"] = \"C:\\\\Users\\\\kdmen\\\\Repos\\\\fl-gestures\\\\April_25\\\\MOE\\\\full_datasplit_dfs\\\\\"\n",
    "config[\"dfs_load_path\"] = \"C:\\\\Users\\\\kdmen\\\\Repos\\\\fl-gestures\\\\April_25\\\\MOE\\\\full_datasplit_dfs\\\\Initial_Multimodal\\\\\"\n",
    "#config[\"saved_df_timestamp\"] = '20250917_1217'\n",
    "# These need to get set by the json split right... are those set somewhere... --> THESE ARE HARDCODED IN load_multimodal_data_loaders right now!!\n",
    "#train_PIDs=['P104', 'P105', 'P106', 'P107', 'P108', 'P109', 'P112', 'P114', 'P115', 'P116', 'P118', 'P119', 'P123', 'P124', 'P125', 'P126', 'P127', 'P128', 'P004', 'P005', 'P006', 'P008', 'P010', 'P011'], \n",
    "#val_PIDs=['P102', 'P110', 'P121', 'P131'], \n",
    "#test_PIDs=['P103', 'P111', 'P122', 'P132'], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5d488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "# TODO: This needs to be updated to use config instead of default values...\n",
    "## And to accomodate k-fold cross validation...\n",
    "def load_multimodal_datasets(config, use_emg=True, use_imu=True, use_demographics=True, load_existing_dfs=False, save_dfs=False):\n",
    "\n",
    "    if use_emg is False or use_imu is False or use_demographics is False:\n",
    "        raise ValueError(\"Currently, emg, imu, and demographics all must be used.\")\n",
    "\n",
    "    emg_imu_pkl_full_path = config[\"emg_imu_pkl_full_path\"]\n",
    "    pwmd_xlsx_filepath = config[\"pwmd_xlsx_filepath\"]\n",
    "    pwoutmd_xlsx_filepath = config[\"pwoutmd_xlsx_filepath\"]\n",
    "    dfs_save_path = config[\"dfs_save_path\"]\n",
    "    dfs_load_path = config[\"dfs_load_path\"]\n",
    "    saved_df_timestamp = config[\"saved_df_timestamp\"]\n",
    "    \n",
    "    # This is the user split... should be set according to the json? Double check...\n",
    "    train_PIDs = config[\"train_PIDs\"]\n",
    "    val_PIDs = config[\"val_PIDs\"]\n",
    "    test_PIDs = config[\"test_PIDs\"]\n",
    "    train_gesture_range = config[\"train_gesture_range\"] \n",
    "    valtest_gesture_range = config[\"valtest_gesture_range\"]\n",
    "\n",
    "    # ----------------\n",
    "    # Build / load DataFrames\n",
    "    # ----------------\n",
    "    if load_existing_dfs is False:\n",
    "        data_df = pd.read_pickle(emg_imu_pkl_full_path)\n",
    "\n",
    "        metadata_cols = ['Participant', 'Gesture_ID', 'Gesture_Num']\n",
    "        metadata_cols_df = data_df[metadata_cols].rename(columns={\"Participant\": \"PID\"})\n",
    "        metadata_cols_df['Gesture_Num'] = metadata_cols_df['Gesture_Num'].astype(int)\n",
    "\n",
    "        # PID encoder\n",
    "        all_PIDs = metadata_cols_df['PID']\n",
    "        unique_PIDs = all_PIDs.unique()\n",
    "        PID_encoder = LabelEncoder().fit(unique_PIDs)\n",
    "\n",
    "        # Gesture encoder\n",
    "        gesture_ID_label_encoder = LabelEncoder()\n",
    "        metadata_cols_df['Enc_Gesture_ID'] = gesture_ID_label_encoder.fit_transform(metadata_cols_df['Gesture_ID'])\n",
    "        metadata_cols_df['Enc_PID'] = PID_encoder.transform(metadata_cols_df['PID'])\n",
    "\n",
    "        # Signals\n",
    "        X_df = data_df.drop(metadata_cols, axis=1)\n",
    "        ppd_B_X_df = preprocess_df_B_by_gesture(X_df)\n",
    "\n",
    "        # Demographics (with & without disabilities)\n",
    "        FULL_pwmd_demo_df = pd.read_excel(pwmd_xlsx_filepath)\n",
    "        pwmd_demo_df = FULL_pwmd_demo_df[[\n",
    "            \"PID\", \"disability coding\", \"time disabled\", \"Actual handedness\",\n",
    "            \"What is your age?\", \"What is your gender?\", \"BMI\", \"DASH score\"\n",
    "        ]][:-8]\n",
    "        pwmd_demo_df[\"time disabled\"] = pd.to_numeric(pwmd_demo_df[\"time disabled\"].astype(str).strip(), errors='coerce')\n",
    "        numeric_cols = pwmd_demo_df.select_dtypes(include='number').columns\n",
    "        pwmd_demo_df[numeric_cols] = pwmd_demo_df[numeric_cols] / 100.0\n",
    "        pwmd_demo_df[\"BMI\"] = pwmd_demo_df[\"BMI\"] / 70.0\n",
    "        pwmd_demo_df['Enc_PID'] = PID_encoder.transform(pwmd_demo_df[\"PID\"])\n",
    "\n",
    "        FULL_pwoutmd_demo_df = pd.read_excel(pwoutmd_xlsx_filepath)\n",
    "        pwoutmd_demo_df = FULL_pwoutmd_demo_df[[\n",
    "            \"PID\", \"disability coding\", \"time disabled\", \"Actual handedness\",\n",
    "            \"What is your age?\", \"What is your gender?\", \"BMI\", \"DASH score\"\n",
    "        ]][:-5]\n",
    "        pwoutmd_demo_df[\"time disabled\"] = pd.to_numeric(pwoutmd_demo_df[\"time disabled\"].astype(str).strip(), errors='coerce')\n",
    "        numeric_cols2 = pwoutmd_demo_df.select_dtypes(include='number').columns\n",
    "        pwoutmd_demo_df[numeric_cols2] = pwoutmd_demo_df[numeric_cols2] / 100.0\n",
    "        pwoutmd_demo_df[\"BMI\"] = pwoutmd_demo_df[\"BMI\"] / 70.0\n",
    "        pwoutmd_demo_df = pwoutmd_demo_df[~pwoutmd_demo_df['PID'].isin(['P001', 'P003'])]\n",
    "        pwoutmd_demo_df['Enc_PID'] = PID_encoder.transform(pwoutmd_demo_df[\"PID\"])\n",
    "\n",
    "        combined_demo_df = pd.concat([pwmd_demo_df, pwoutmd_demo_df])\n",
    "        demoENC_df = pd.get_dummies(\n",
    "            combined_demo_df,\n",
    "            columns=[\"disability coding\", \"Actual handedness\", \"What is your gender?\"],\n",
    "            drop_first=True\n",
    "        )\n",
    "        demoENC_df.drop(columns=[\"PID\"], inplace=True)  # keep Enc_PID only\n",
    "\n",
    "        full_yX_timeseries_df = pd.concat([metadata_cols_df, ppd_B_X_df], axis=1)\n",
    "\n",
    "        # Classic fixed splits (still used either for classic loaders OR to form merged pools)\n",
    "        train_support_df = full_yX_timeseries_df[\n",
    "            (full_yX_timeseries_df['PID'].isin(train_PIDs)) &\n",
    "            (full_yX_timeseries_df['Gesture_Num'].isin(train_gesture_range))\n",
    "        ]\n",
    "        train_query_df = full_yX_timeseries_df[\n",
    "            (full_yX_timeseries_df['PID'].isin(train_PIDs)) &\n",
    "            (full_yX_timeseries_df['Gesture_Num'] == 10)\n",
    "        ]\n",
    "\n",
    "        val_support_df = full_yX_timeseries_df[\n",
    "            (full_yX_timeseries_df['PID'].isin(val_PIDs)) &\n",
    "            (full_yX_timeseries_df['Gesture_Num'] == 1)\n",
    "        ]\n",
    "        val_query_df = full_yX_timeseries_df[\n",
    "            (full_yX_timeseries_df['PID'].isin(val_PIDs)) &\n",
    "            (full_yX_timeseries_df['Gesture_Num'].isin(valtest_gesture_range))\n",
    "        ]\n",
    "\n",
    "        test_support_df = full_yX_timeseries_df[\n",
    "            (full_yX_timeseries_df['PID'].isin(test_PIDs)) &\n",
    "            (full_yX_timeseries_df['Gesture_Num'] == 1)\n",
    "        ]\n",
    "        test_query_df = full_yX_timeseries_df[\n",
    "            (full_yX_timeseries_df['PID'].isin(test_PIDs)) &\n",
    "            (full_yX_timeseries_df['Gesture_Num'].isin(valtest_gesture_range))\n",
    "        ]\n",
    "\n",
    "        emg_cols = [c for c in ppd_B_X_df.columns if c.startswith(\"EMG\")]\n",
    "        imu_cols = [c for c in ppd_B_X_df.columns if c.startswith(\"IMU\")]\n",
    "        demo_cols = demoENC_df.columns\n",
    "\n",
    "        if save_dfs:\n",
    "            train_support_df.to_pickle(f\"{dfs_save_path}{config['timestamp']}_train_support_df.pkl\")\n",
    "            train_query_df.to_pickle(f\"{dfs_save_path}{config['timestamp']}_train_query_df.pkl\")\n",
    "            val_support_df.to_pickle(f\"{dfs_save_path}{config['timestamp']}_val_support_df.pkl\")\n",
    "            val_query_df.to_pickle(f\"{dfs_save_path}{config['timestamp']}_val_query_df.pkl\")\n",
    "            test_support_df.to_pickle(f\"{dfs_save_path}{config['timestamp']}_test_support_df.pkl\")\n",
    "            test_query_df.to_pickle(f\"{dfs_save_path}{config['timestamp']}_test_query_df.pkl\")\n",
    "            demoENC_df.to_pickle(f\"{dfs_save_path}{config['timestamp']}_demoENC_df.pkl\")\n",
    "            with open(f\"{dfs_save_path}{config['timestamp']}_columns.pkl\", \"wb\") as f:\n",
    "                pickle.dump([emg_cols, imu_cols, list(demo_cols)], f)\n",
    "            print(\"Dataframes have been saved!\")\n",
    "\n",
    "    else:  # ie if our datasets already exist\n",
    "        #print(f\"dfs_load_path: {dfs_load_path}\")\n",
    "        train_support_df = pd.read_pickle(f\"{dfs_load_path}{saved_df_timestamp}_train_support_df.pkl\")\n",
    "        train_query_df = pd.read_pickle(f\"{dfs_load_path}{saved_df_timestamp}_train_query_df.pkl\")\n",
    "        val_support_df = pd.read_pickle(f\"{dfs_load_path}{saved_df_timestamp}_val_support_df.pkl\")\n",
    "        val_query_df = pd.read_pickle(f\"{dfs_load_path}{saved_df_timestamp}_val_query_df.pkl\")\n",
    "        test_support_df = pd.read_pickle(f\"{dfs_load_path}{saved_df_timestamp}_test_support_df.pkl\")\n",
    "        test_query_df = pd.read_pickle(f\"{dfs_load_path}{saved_df_timestamp}_test_query_df.pkl\")\n",
    "        demoENC_df = pd.read_pickle(f\"{dfs_load_path}{saved_df_timestamp}_demoENC_df.pkl\")\n",
    "        with open(f\"{dfs_load_path}{saved_df_timestamp}_columns.pkl\", \"rb\") as f:\n",
    "            emg_cols, imu_cols, demo_cols = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "def _B_normalize_block(block_np, demean=True, eps=1e-8):\n",
    "    \"\"\"\n",
    "    block_np: (T, D_block) numpy array for one biosignal (e.g., all IMU channels)\n",
    "    Returns: (T, D_block) normalized per $B (demean per channel, divide by shared std over block)\n",
    "    \"\"\"\n",
    "    if demean:\n",
    "        block_np = block_np - block_np.mean(axis=0, keepdims=True)  # per-channel demean\n",
    "    sigma = block_np.ravel().std(dtype=np.float64)\n",
    "    if sigma < eps:\n",
    "        return block_np  # flat signal; leave as-is\n",
    "    return block_np / sigma\n",
    "\n",
    "def preprocess_df_B_by_gesture(\n",
    "    data_df: pd.DataFrame,\n",
    "    biosignal_switch_ix: int = 72,   # [:switch) = IMU, [switch:] = EMG\n",
    "    trial_length: int = 64,\n",
    "    demean: bool = True,\n",
    "    eps: float = 1e-8,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply $B to every trial in the full dataframe.\n",
    "    Assumptions:\n",
    "      - data_df has ONLY sensor columns (no metadata), shape = (num_trials*trial_length, num_channels)\n",
    "      - IMU columns come first, EMG columns follow\n",
    "      - Each trial is a contiguous block of `trial_length` rows\n",
    "    Returns: DataFrame with same shape/columns as input.\n",
    "    \"\"\"\n",
    "    if data_df.isna().any().any():\n",
    "        print(\"Warning: NaNs detected in input; consider cleaning first.\")\n",
    "\n",
    "    num_rows, num_cols = data_df.shape\n",
    "    if num_rows % trial_length != 0:\n",
    "        raise ValueError(f\"Rows ({num_rows}) not divisible by trial_length ({trial_length}).\")\n",
    "\n",
    "    if not (0 < biosignal_switch_ix < num_cols):\n",
    "        raise ValueError(f\"biosignal_switch_ix {biosignal_switch_ix} must be in (0, {num_cols}).\")\n",
    "\n",
    "    num_trials = num_rows // trial_length\n",
    "    cols = data_df.columns\n",
    "    X = data_df.to_numpy(dtype=np.float64, copy=True)  # (N, D)\n",
    "\n",
    "    for t in range(num_trials):\n",
    "        s = t * trial_length\n",
    "        e = s + trial_length\n",
    "        trial = X[s:e, :]  # (T, D)\n",
    "\n",
    "        imu_block = trial[:, :biosignal_switch_ix]\n",
    "        emg_block = trial[:, biosignal_switch_ix:]\n",
    "\n",
    "        imu_block = _B_normalize_block(imu_block, demean=demean, eps=eps)\n",
    "        emg_block = _B_normalize_block(emg_block, demean=demean, eps=eps)\n",
    "\n",
    "        X[s:e, :biosignal_switch_ix] = imu_block\n",
    "        X[s:e, biosignal_switch_ix:] = emg_block\n",
    "\n",
    "    out = pd.DataFrame(X, columns=cols, index=data_df.index)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4078286d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
